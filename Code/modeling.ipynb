{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn import feature_selection as fs\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Using Random Forest\n",
    "\n",
    "Ada beberapa yang dilakukan saat melakukan pemodelan dengan menggunakan random forest, diantaranya:\n",
    "1. Feature\n",
    "2. Text Only\n",
    "3. Feature Engineering and Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"..\\Data\\Assets\\dataCleaning.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video_Id</th>\n",
       "      <th>Tittle</th>\n",
       "      <th>Description</th>\n",
       "      <th>Name</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Comment_Id</th>\n",
       "      <th>Time</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Reply_Count</th>\n",
       "      <th>Label</th>\n",
       "      <th>...</th>\n",
       "      <th>CountUpperLetters</th>\n",
       "      <th>SimilarityTitle</th>\n",
       "      <th>SimilarityDesc</th>\n",
       "      <th>LenComment</th>\n",
       "      <th>NameLen</th>\n",
       "      <th>UrlRatio</th>\n",
       "      <th>LexicalRichness</th>\n",
       "      <th>LexicalDensity</th>\n",
       "      <th>CommentRandomness</th>\n",
       "      <th>NameRandomness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2922</th>\n",
       "      <td>AP0NACavjfk</td>\n",
       "      <td>SkinnyIndonesian24 | Prabowo VS Jokowi - Epic ...</td>\n",
       "      <td>SkinnyIndonesian24 ( Andovi da Lopez sebagai J...</td>\n",
       "      <td>Mulky 57</td>\n",
       "      <td>Jokowi Jokowi Jokowi Jokowi Jokowi Jokowi Joko...</td>\n",
       "      <td>Ugxqz2usP6dWtNC3It94AaABAg</td>\n",
       "      <td>2022-03-03 04:59:16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>62</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.040579</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Video_Id                                             Tittle  \\\n",
       "2922  AP0NACavjfk  SkinnyIndonesian24 | Prabowo VS Jokowi - Epic ...   \n",
       "\n",
       "                                            Description      Name  \\\n",
       "2922  SkinnyIndonesian24 ( Andovi da Lopez sebagai J...  Mulky 57   \n",
       "\n",
       "                                                Comment  \\\n",
       "2922  Jokowi Jokowi Jokowi Jokowi Jokowi Jokowi Joko...   \n",
       "\n",
       "                      Comment_Id                 Time  Likes  Reply_Count  \\\n",
       "2922  Ugxqz2usP6dWtNC3It94AaABAg  2022-03-03 04:59:16      2            0   \n",
       "\n",
       "           Label  ... CountUpperLetters SimilarityTitle SimilarityDesc  \\\n",
       "2922  legitimate  ...                 9             1.0       0.111111   \n",
       "\n",
       "      LenComment  NameLen  UrlRatio  LexicalRichness  LexicalDensity  \\\n",
       "2922          62        8       0.0        11.111111           100.0   \n",
       "\n",
       "      CommentRandomness  NameRandomness  \n",
       "2922           0.040579           0.375  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banyaknya Baris dan Kolom adalah 3000 dan 31\n"
     ]
    }
   ],
   "source": [
    "B, K = data.shape\n",
    "print(f\"Banyaknya Baris dan Kolom adalah {B} dan {K}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 31 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Video_Id             3000 non-null   object \n",
      " 1   Tittle               3000 non-null   object \n",
      " 2   Description          3000 non-null   object \n",
      " 3   Name                 3000 non-null   object \n",
      " 4   Comment              3000 non-null   object \n",
      " 5   Comment_Id           3000 non-null   object \n",
      " 6   Time                 3000 non-null   object \n",
      " 7   Likes                3000 non-null   int64  \n",
      " 8   Reply_Count          3000 non-null   int64  \n",
      " 9   Label                3000 non-null   object \n",
      " 10  cleanTittle          3000 non-null   object \n",
      " 11  cleanComment         2999 non-null   object \n",
      " 12  cleanDesc            3000 non-null   object \n",
      " 13  LengthSentence       3000 non-null   int64  \n",
      " 14  CommentLength        3000 non-null   int64  \n",
      " 15  countUrl             3000 non-null   int64  \n",
      " 16  WhiteSpacenum        3000 non-null   int64  \n",
      " 17  StopwordRatio        3000 non-null   float64\n",
      " 18  WorldDuplicateRatio  3000 non-null   float64\n",
      " 19  CountEmoji           3000 non-null   int64  \n",
      " 20  CountNonAscii        3000 non-null   int64  \n",
      " 21  CountUpperLetters    3000 non-null   int64  \n",
      " 22  SimilarityTitle      3000 non-null   float64\n",
      " 23  SimilarityDesc       3000 non-null   float64\n",
      " 24  LenComment           3000 non-null   int64  \n",
      " 25  NameLen              3000 non-null   int64  \n",
      " 26  UrlRatio             3000 non-null   float64\n",
      " 27  LexicalRichness      3000 non-null   float64\n",
      " 28  LexicalDensity       3000 non-null   float64\n",
      " 29  CommentRandomness    3000 non-null   float64\n",
      " 30  NameRandomness       3000 non-null   float64\n",
      "dtypes: float64(9), int64(11), object(11)\n",
      "memory usage: 726.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Time\"] = data[\"Time\"].astype(\"datetime64\")\n",
    "#data[\"Label\"] = data[\"Label\"].astype(\"category\")\n",
    "data[\"Video_Id\"] = data[\"Video_Id\"].astype(\"category\")\n",
    "data[\"Comment_Id\"] = data[\"Comment_Id\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Video_Id               0\n",
       "Tittle                 0\n",
       "Description            0\n",
       "Name                   0\n",
       "Comment                0\n",
       "Comment_Id             0\n",
       "Time                   0\n",
       "Likes                  0\n",
       "Reply_Count            0\n",
       "Label                  0\n",
       "cleanTittle            0\n",
       "cleanComment           1\n",
       "cleanDesc              0\n",
       "LengthSentence         0\n",
       "CommentLength          0\n",
       "countUrl               0\n",
       "WhiteSpacenum          0\n",
       "StopwordRatio          0\n",
       "WorldDuplicateRatio    0\n",
       "CountEmoji             0\n",
       "CountNonAscii          0\n",
       "CountUpperLetters      0\n",
       "SimilarityTitle        0\n",
       "SimilarityDesc         0\n",
       "LenComment             0\n",
       "NameLen                0\n",
       "UrlRatio               0\n",
       "LexicalRichness        0\n",
       "LexicalDensity         0\n",
       "CommentRandomness      0\n",
       "NameRandomness         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Video_Id               0\n",
       "Tittle                 0\n",
       "Description            0\n",
       "Name                   0\n",
       "Comment                0\n",
       "Comment_Id             0\n",
       "Time                   0\n",
       "Likes                  0\n",
       "Reply_Count            0\n",
       "Label                  0\n",
       "cleanTittle            0\n",
       "cleanComment           0\n",
       "cleanDesc              0\n",
       "LengthSentence         0\n",
       "CommentLength          0\n",
       "countUrl               0\n",
       "WhiteSpacenum          0\n",
       "StopwordRatio          0\n",
       "WorldDuplicateRatio    0\n",
       "CountEmoji             0\n",
       "CountNonAscii          0\n",
       "CountUpperLetters      0\n",
       "SimilarityTitle        0\n",
       "SimilarityDesc         0\n",
       "LenComment             0\n",
       "NameLen                0\n",
       "UrlRatio               0\n",
       "LexicalRichness        0\n",
       "LexicalDensity         0\n",
       "CommentRandomness      0\n",
       "NameRandomness         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 31)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category(x):\n",
    "    if x=='spam':\n",
    "        return 1\n",
    "    else :\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Label=data.Label.apply(lambda x:category(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Video_Id\"] = df[\"Video_Id\"].cat.codes\n",
    "df[\"Comment_Id\"] = df[\"Comment_Id\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video_Id</th>\n",
       "      <th>Tittle</th>\n",
       "      <th>Description</th>\n",
       "      <th>Name</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Comment_Id</th>\n",
       "      <th>Time</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Reply_Count</th>\n",
       "      <th>Label</th>\n",
       "      <th>...</th>\n",
       "      <th>CountUpperLetters</th>\n",
       "      <th>SimilarityTitle</th>\n",
       "      <th>SimilarityDesc</th>\n",
       "      <th>LenComment</th>\n",
       "      <th>NameLen</th>\n",
       "      <th>UrlRatio</th>\n",
       "      <th>LexicalRichness</th>\n",
       "      <th>LexicalDensity</th>\n",
       "      <th>CommentRandomness</th>\n",
       "      <th>NameRandomness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>1</td>\n",
       "      <td>SkinnyIndonesian24 | Prabowo VS Jokowi - Epic ...</td>\n",
       "      <td>SkinnyIndonesian24 ( Andovi da Lopez sebagai J...</td>\n",
       "      <td>Fikri KRN</td>\n",
       "      <td>Sekedar Berbagi Info\\nDownload Aplikasi iMeme ...</td>\n",
       "      <td>2936</td>\n",
       "      <td>2019-04-14 11:29:40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>255</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.170732</td>\n",
       "      <td>63.414634</td>\n",
       "      <td>0.016177</td>\n",
       "      <td>0.327523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Video_Id                                             Tittle  \\\n",
       "641         1  SkinnyIndonesian24 | Prabowo VS Jokowi - Epic ...   \n",
       "\n",
       "                                           Description       Name  \\\n",
       "641  SkinnyIndonesian24 ( Andovi da Lopez sebagai J...  Fikri KRN   \n",
       "\n",
       "                                               Comment  Comment_Id  \\\n",
       "641  Sekedar Berbagi Info\\nDownload Aplikasi iMeme ...        2936   \n",
       "\n",
       "                   Time  Likes  Reply_Count  Label  ... CountUpperLetters  \\\n",
       "641 2019-04-14 11:29:40      0            0      1  ...                46   \n",
       "\n",
       "    SimilarityTitle SimilarityDesc  LenComment  NameLen  UrlRatio  \\\n",
       "641             0.0           0.04         255        9       0.0   \n",
       "\n",
       "     LexicalRichness  LexicalDensity  CommentRandomness  NameRandomness  \n",
       "641        73.170732       63.414634           0.016177        0.327523  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = [\"Likes\",\"Reply_Count\", \"LengthSentence\", \"countUrl\", \"WhiteSpacenum\",\n",
    "            \"StopwordRatio\", \"WorldDuplicateRatio\", \"CountEmoji\", \"CountNonAscii\",\n",
    "            \"CountUpperLetters\", \"SimilarityTitle\", \"SimilarityDesc\",\"LenComment\", \n",
    "            \"NameLen\", \"UrlRatio\",\"LexicalRichness\", \"LexicalDensity\", \"CommentRandomness\",\n",
    "            \"NameRandomness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"cleanComment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = np.array(df[text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = np.array(df[feature])\n",
    "labels = np.array(df[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['https://youtu.be/lbkgyxnpmcu'],\n",
       "       ['bantu subscribe youtube gw dong'],\n",
       "       ['hachimon tonkou kalau buka gerbang ke 8 auto mati wkwkkw'],\n",
       "       ...,\n",
       "       ['keunggulan dan kekurangan nge buat kita semua jadi bingung milih'],\n",
       "       ['keren parahhh'],\n",
       "       ['mereka harus nonton nih']], dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 1.00000000e+00, ...,\n",
       "        1.00000000e+02, 1.45843463e-01, 1.47430008e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, ...,\n",
       "        4.00000000e+01, 1.22351806e-01, 2.57080208e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, ...,\n",
       "        5.00000000e+01, 6.85953186e-02, 2.00798303e-01],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, ...,\n",
       "        6.00000000e+01, 5.83109093e-02, 1.16132453e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, ...,\n",
       "        1.00000000e+02, 2.21010822e-01, 2.26562500e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, ...,\n",
       "        5.00000000e+01, 1.53661697e-01, 5.00000000e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Before Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Modeling Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Without selection feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(feat,\n",
    "                                                                            labels,\n",
    "                                                                            test_size=0.3,\n",
    "                                                                            random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = [{\n",
    "                'n_estimators':[10, 50, 100, 200, 500],\n",
    "                'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                'max_depth': [5, 10, 15, 20, 25, 50, None]\n",
    "                'class_weight': ['balanced']\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = GridSearchCV(model, param_grid=parameter, scoring='f1', cv=10, n_jobs=-1, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 75 candidates, totalling 750 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(random_state=99),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'class_weight': ['balanced'],\n",
       "                          'max_depth': [5, 10, 15, 20, 25],\n",
       "                          'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                          'n_estimators': [10, 50, 100, 200, 500]}],\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'max_depth': 25,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.8508771929824561, 0.8388595970985374)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.score(features_train, labels_train), cv.score(features_test, labels_test), cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Selection feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_folds = StratifiedKFold(n_splits=4, shuffle = True, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = fs.RFECV(model, cv = feature_folds, scoring = 'f1', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True,  True,  True, False, False, False,\n",
       "        True, False,  True,  True,  True,  True, False,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector = selector.fit(features_train, np.ravel(labels_train))\n",
    "selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking after RFECV:\n",
      "[3 9 8 1 1 1 6 7 4 1 5 1 1 1 1 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature ranking after RFECV:\")\n",
    "print(selector.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen important features:\n",
      "['countUrl', 'WhiteSpacenum', 'StopwordRatio', 'CountUpperLetters', 'SimilarityDesc', 'LenComment', 'NameLen', 'UrlRatio', 'LexicalDensity', 'CommentRandomness', 'NameRandomness']\n"
     ]
    }
   ],
   "source": [
    "ranks_transform = list(np.transpose(selector.ranking_))\n",
    "chosen_features = [i for i,j in zip(feature,ranks_transform) if j==1]\n",
    "print(\"Chosen important features:\")\n",
    "print(chosen_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training subset shape before the recursive feature elimination:\n",
      "(2399, 19)\n",
      "Training subset array shape after the recursive feature elimination:\n",
      "(2399, 11)\n",
      "Test subset array shape after the recursive feature elimination:\n",
      "(600, 11)\n"
     ]
    }
   ],
   "source": [
    "features_train_reduced = selector.transform(features_train)\n",
    "features_test_reduced = selector.transform(features_test)\n",
    "\n",
    "print(\"Training subset shape before the recursive feature elimination:\")\n",
    "print(features_train.shape)\n",
    "print(\"Training subset array shape after the recursive feature elimination:\")\n",
    "print(features_train_reduced.shape)\n",
    "print(\"Test subset array shape after the recursive feature elimination:\")\n",
    "print(features_test_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1 = GridSearchCV(model, param_grid=parameter, scoring='f1', cv=10, return_train_score=True, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 75 candidates, totalling 750 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(random_state=99),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'class_weight': ['balanced'],\n",
       "                          'max_depth': [5, 10, 15, 20, 25],\n",
       "                          'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                          'n_estimators': [10, 50, 100, 200, 500]}],\n",
       "             return_train_score=True, scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv1.fit(features_train_reduced,labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'max_depth': 20,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.8268398268398269, 0.8307395080951956)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv1.score(features_train_reduced, labels_train), cv1.score(features_test_reduced, labels_test), cv1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "\n",
    "### **Modeling Text Only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, text_test, labels_train, labels_test = train_test_split(df['cleanComment'],\n",
    "                                                                    df[\"Label\"],\n",
    "                                                                    test_size=0.3,\n",
    "                                                                    random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_vectorizer.fit(text_train)\n",
    "#Xtrain_tfidf = tfidf_vectorizer.transform(text_train.values.tolist())\n",
    "#Xtest_tfidf = tfidf_vectorizer.transform(text_train.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = RandomForestClassifier(random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipeline = make_pipeline(CountVectorizer(),\n",
    "                         TfidfTransformer(norm=None),\n",
    "                         RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = {\n",
    "    'countvectorizer__max_features': (None, 1000, 2000),\n",
    "    'countvectorizer__ngram_range': ((1, 1), (1, 2)),   # unigrams or bigrams\n",
    "    #'countvectorizer__stop_words': ('english', None),\n",
    "    'tfidftransformer__use_idf': (True, False),  # effectively turn on/off tfidf\n",
    "    'randomforestclassifier__n_estimators': (20, 50, 100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2 = GridSearchCV(pipeline, param_grid=parameter, cv=10, scoring='f1', n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
       "                                       ('tfidftransformer',\n",
       "                                        TfidfTransformer(norm=None)),\n",
       "                                       ('randomforestclassifier',\n",
       "                                        RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'countvectorizer__max_features': (None, 1000, 2000),\n",
       "                         'countvectorizer__ngram_range': ((1, 1), (1, 2)),\n",
       "                         'randomforestclassifier__n_estimators': (20, 50, 100),\n",
       "                         'tfidftransformer__use_idf': (True, False)},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.fit(text_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'countvectorizer', 'tfidftransformer', 'randomforestclassifier', 'countvectorizer__analyzer', 'countvectorizer__binary', 'countvectorizer__decode_error', 'countvectorizer__dtype', 'countvectorizer__encoding', 'countvectorizer__input', 'countvectorizer__lowercase', 'countvectorizer__max_df', 'countvectorizer__max_features', 'countvectorizer__min_df', 'countvectorizer__ngram_range', 'countvectorizer__preprocessor', 'countvectorizer__stop_words', 'countvectorizer__strip_accents', 'countvectorizer__token_pattern', 'countvectorizer__tokenizer', 'countvectorizer__vocabulary', 'tfidftransformer__norm', 'tfidftransformer__smooth_idf', 'tfidftransformer__sublinear_tf', 'tfidftransformer__use_idf', 'randomforestclassifier__bootstrap', 'randomforestclassifier__ccp_alpha', 'randomforestclassifier__class_weight', 'randomforestclassifier__criterion', 'randomforestclassifier__max_depth', 'randomforestclassifier__max_features', 'randomforestclassifier__max_leaf_nodes', 'randomforestclassifier__max_samples', 'randomforestclassifier__min_impurity_decrease', 'randomforestclassifier__min_samples_leaf', 'randomforestclassifier__min_samples_split', 'randomforestclassifier__min_weight_fraction_leaf', 'randomforestclassifier__n_estimators', 'randomforestclassifier__n_jobs', 'randomforestclassifier__oob_score', 'randomforestclassifier__random_state', 'randomforestclassifier__verbose', 'randomforestclassifier__warm_start'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.estimator.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countvectorizer__max_features': 2000,\n",
       " 'countvectorizer__ngram_range': (1, 1),\n",
       " 'randomforestclassifier__n_estimators': 100,\n",
       " 'tfidftransformer__use_idf': False}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9978046103183316, 0.9743589743589743, 0.9789386081360009)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.score(text_train, labels_train), cv2.score(text_test, labels_test), cv2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "\n",
    "### **Modeling FE + Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df, val_df, test_df = np.split(df1.sample(frac=1), [int(.8*len(df1)), int(.9 * len(df1))])\n",
    "#train_df.to_csv('../Data/Assets/train.csv')\n",
    "#val_df.to_csv('../Data/Assets/val.csv')\n",
    "#test_df.to_csv('../Data/Assets/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.read_csv(\"../Data/Assets/train.csv\")\n",
    "#val = pd.read_csv(\"../Data/Assets/val.csv\")\n",
    "#test = pd.read_csv(\"../Data/Assets/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = pd.concat([train, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Video_Id', 'Tittle', 'Description', 'Name', 'Comment', 'Comment_Id',\n",
       "       'Time', 'Likes', 'Reply_Count', 'Label', 'cleanTittle', 'cleanComment',\n",
       "       'cleanDesc', 'LengthSentence', 'CommentLength', 'countUrl',\n",
       "       'WhiteSpacenum', 'StopwordRatio', 'WorldDuplicateRatio', 'CountEmoji',\n",
       "       'CountNonAscii', 'CountUpperLetters', 'SimilarityTitle',\n",
       "       'SimilarityDesc', 'LenComment', 'NameLen', 'UrlRatio',\n",
       "       'LexicalRichness', 'LexicalDensity', 'CommentRandomness',\n",
       "       'NameRandomness'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer            =  TfidfVectorizer()\n",
    "#train_tf_idf_features =  vectorizer.fit_transform(df2[\"cleanComment\"]).toarray()\n",
    "#test_tf_idf_features  =  vectorizer.fit_transform(test[\"cleanComment\"]).toarray()\n",
    "\n",
    "# Converting above list to DataFrame\n",
    "#train_tf_idf          = pd.DataFrame(train_tf_idf_features)\n",
    "#test_tf_idf           = pd.DataFrame(test_tf_idf_features)\n",
    "\n",
    "# Saparating train and test labels from all features\n",
    "#train_y = df2[\"Label\"]\n",
    "#test_y = test[\"Label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Using TF-IDF Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer            =  TfidfVectorizer()\n",
    "train_tf_idf_features =  vectorizer.fit_transform(df1[\"cleanComment\"]).toarray()\n",
    "#test_tf_idf_features  =  vectorizer.fit_transform(test[\"cleanComment\"]).toarray()\n",
    "\n",
    "# Converting above list to DataFrame\n",
    "train_tf_idf          = pd.DataFrame(train_tf_idf_features)\n",
    "\n",
    "\n",
    "# Saparating train and test labels from all features\n",
    "train_y = df1[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train_tf_idf,df1[feature],left_index=True, right_index=True)\n",
    "#test  = pd.merge(test_tf_idf,test[feature],left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>CountUpperLetters</th>\n",
       "      <th>SimilarityTitle</th>\n",
       "      <th>SimilarityDesc</th>\n",
       "      <th>LenComment</th>\n",
       "      <th>NameLen</th>\n",
       "      <th>UrlRatio</th>\n",
       "      <th>LexicalRichness</th>\n",
       "      <th>LexicalDensity</th>\n",
       "      <th>CommentRandomness</th>\n",
       "      <th>NameRandomness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>0.109372</td>\n",
       "      <td>0.194209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 7335 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9  ...  CountUpperLetters  \\\n",
       "868  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...                  2   \n",
       "\n",
       "     SimilarityTitle  SimilarityDesc  LenComment  NameLen  UrlRatio  \\\n",
       "868              0.0             0.0          38       20       0.0   \n",
       "\n",
       "     LexicalRichness  LexicalDensity  CommentRandomness  NameRandomness  \n",
       "868            100.0       14.285714           0.109372        0.194209  \n",
       "\n",
       "[1 rows x 7335 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, labels_train, labels_test = train_test_split(train,\n",
    "                                                              train_y,\n",
    "                                                              test_size=0.3,\n",
    "                                                              random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = [{\n",
    "                'n_estimators':[10, 20, 30, 40, 50, 100, 200, 500],\n",
    "                'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                'max_depth': [5, 10, 15, 20, 25, 50, None],\n",
    "                'class_weight': ['balanced']\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring Using F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv3 = GridSearchCV(model, param_grid=parameter, scoring='f1', cv=10, return_train_score=True, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 75 candidates, totalling 750 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(random_state=99),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'class_weight': ['balanced'],\n",
       "                          'max_depth': [5, 10, 15, 20, 25],\n",
       "                          'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                          'n_estimators': [10, 50, 100, 200, 500]}],\n",
       "             return_train_score=True, scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv3.fit(X_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'max_depth': 20,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 10}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6862996158770805, 0.40930232558139534, 0.4265068570530686)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv3.score(X_train, labels_train), cv3.score(X_test, labels_test), cv3.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring Using Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv4 = GridSearchCV(model, param_grid=parameter, scoring='accuracy', cv=10, return_train_score=True, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 75 candidates, totalling 750 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(random_state=99),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'class_weight': ['balanced'],\n",
       "                          'max_depth': [5, 10, 15, 20, 25],\n",
       "                          'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                          'n_estimators': [10, 50, 100, 200, 500]}],\n",
       "             return_train_score=True, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv4.fit(X_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'max_depth': 5,\n",
       " 'max_features': 'log2',\n",
       " 'n_estimators': 10}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4737956590788777, 0.44320987654320987, 0.5494596420128335)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv4.score(X_train, labels_train), cv4.score(X_test, labels_test), cv4.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Using CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 31)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer            =  CountVectorizer()\n",
    "train_cv_features     =  vectorizer.fit_transform(df2[\"cleanComment\"]).toarray()\n",
    "#test_tf_idf_features  =  vectorizer.fit_transform(test[\"cleanComment\"]).toarray()\n",
    "\n",
    "# Converting above list to DataFrame\n",
    "train_cv         = pd.DataFrame(train_cv_features)\n",
    "\n",
    "# Saparating train and test labels from all features\n",
    "train_y = df2[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 7316)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "7311    0\n",
       "7312    0\n",
       "7313    0\n",
       "7314    0\n",
       "7315    0\n",
       "Length: 7316, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cv.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7306</th>\n",
       "      <th>7307</th>\n",
       "      <th>7308</th>\n",
       "      <th>7309</th>\n",
       "      <th>7310</th>\n",
       "      <th>7311</th>\n",
       "      <th>7312</th>\n",
       "      <th>7313</th>\n",
       "      <th>7314</th>\n",
       "      <th>7315</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2999 rows × 7316 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     ...  7306  \\\n",
       "0        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "4        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "2994     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2995     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2996     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2997     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2998     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "      7307  7308  7309  7310  7311  7312  7313  7314  7315  \n",
       "0        0     0     0     0     0     0     0     0     0  \n",
       "1        0     0     0     0     0     0     0     0     0  \n",
       "2        0     0     0     0     0     0     0     0     0  \n",
       "3        0     0     0     0     0     0     0     0     0  \n",
       "4        0     0     0     0     0     0     0     0     0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "2994     0     0     0     0     0     0     0     0     0  \n",
       "2995     0     0     0     0     0     0     0     0     0  \n",
       "2996     0     0     0     0     0     0     0     0     0  \n",
       "2997     0     0     0     0     0     0     0     0     0  \n",
       "2998     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[2999 rows x 7316 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cv.replace(to_replace = np.nan, value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = df2[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 19)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = [{\n",
    "                'n_estimators':[10, 50, 100, 200, 500],\n",
    "                'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                'max_depth': [5, 10, 15, 20, 25],\n",
    "                'class_weight': ['balanced']\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([train, feat], axis=1, join=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train_cv, feat, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2998, 7335)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2998, 7354)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2998, 7335)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 19)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[feature].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999,)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e470a54d1f627e8dbc62884db0ab90c1d014850c7adde4c19b633d3b1a7b860"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
